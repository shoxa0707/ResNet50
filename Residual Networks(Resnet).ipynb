{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3528df-a4cd-467c-9a4c-44d08ccb225c",
   "metadata": {},
   "source": [
    "## Import architectures and necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c6b489-ca83-4f2b-ba7b-1fd19af409be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 10:58:27.546919: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-05 10:58:28.179052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from resnet50 import ResNet50\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c883a0-ca86-4993-8aa7-463c34a56ae9",
   "metadata": {},
   "source": [
    "## Preprocessing images for train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587d2b69-22a8-4bbe-a0db-02bc6978446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "\n",
    "imagesfiles = [i for i in glob('data/*.JPEG')]\n",
    "for i in imagesfiles:\n",
    "    image = cv2.imread(i)/255.0\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    images.append(image)\n",
    "images = np.array(images)\n",
    "\n",
    "with open('data/imagenet_2012_validation_synset_labels.txt') as f:\n",
    "    labelstxt = f.read().split('\\n')[:-1]\n",
    "with open('data/labels.txt') as f:\n",
    "    labs = f.read()\n",
    "    \n",
    "for i in labelstxt:\n",
    "    bosh = labs.find(i)\n",
    "    labels.append(int(labs[bosh+10:bosh+10+labs[bosh+10:].find(' ')])-1)\n",
    "    \n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7002b450-9e9a-40ae-b3b8-62f32d2ee3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 224, 224, 3) (40000,)\n",
      "(10000, 224, 224, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=100)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e89d8f-6673-465a-ae84-cd0c7adf273e",
   "metadata": {},
   "source": [
    "## Generation of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e988c1-c242-41ce-9b77-d6f0dd0cd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bcce87-7305-4fb3-a064-b2a535908bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(x_train, y_train, 32)\n",
    "test_gen = DataGenerator(x_test, y_test, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c048e-4376-4110-82bc-6e8872f3b1d7",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f7aa09-4bce-4915-8b40-d97d5ec115c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 11:02:29.746342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-05 11:02:29.746545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-05 11:02:29.770841: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "class Model(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = ResNet50()\n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d40a92a-a50b-4f06-a19b-337b0b7ba8d4",
   "metadata": {},
   "source": [
    "## Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865518a7-37ee-47dd-8ea7-869ab88522a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6574d70-0e97-47c1-aec1-578f9695763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac7473-7d98-427b-abcc-1b2f815242c8",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e88b5acb-cee1-44bf-9b6d-030fe371c0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airi/anaconda3/lib/python3.9/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.707707405090332, Test Accuracy: 0.11102631688117981%\n",
      "Epoch 1, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.7114763259887695, Test Accuracy: 0.11133906990289688%\n",
      "Epoch 2, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.711477279663086, Test Accuracy: 0.11133906990289688%\n",
      "Epoch 3, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.711477279663086, Test Accuracy: 0.11133906990289688%\n",
      "Epoch 4, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.711477279663086, Test Accuracy: 0.11133906990289688%\n",
      "Epoch 5, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.711477279663086, Test Accuracy: 0.11133906990289688%\n",
      "Epoch 6, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.711477279663086, Test Accuracy: 0.11133906990289688%\n",
      "Epoch 7, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.711477279663086, Test Accuracy: 0.11133906990289688%\n",
      "Epoch 8, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.711477279663086, Test Accuracy: 0.11133906990289688%\n",
      "Epoch 9, Loss: 7.673803806304932, Accuracy: 0.09648437052965164%, Test Loss: 7.711477279663086, Test Accuracy: 0.11133906990289688%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for train_images, train_labels in train_gen:\n",
    "        train_step(train_images, train_labels)\n",
    "\n",
    "    for test_images, test_labels in test_gen:\n",
    "        test_step(test_images, test_labels)\n",
    "    if epoch % 1 == 0:\n",
    "        print(\n",
    "          f'Epoch {epoch}, '\n",
    "          f'Loss: {train_loss.result()}, '\n",
    "          f'Accuracy: {train_accuracy.result() * 100}%, '\n",
    "          f'Test Loss: {test_loss.result()}, '\n",
    "          f'Test Accuracy: {test_accuracy.result() * 100}%'\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f07393a-5520-42b5-a9df-f5627a12652e",
   "metadata": {},
   "source": [
    "## Finetune architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1aaadaf-7eb4-4cc8-8de5-42cc1c9d4cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 13:30:28.009738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [4]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-05-05 13:30:28.010021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [4]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "2023-05-05 13:30:29.590621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [4]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-05 13:30:29.590910: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [4]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3680, 224, 224, 3),\n",
       " (3680,),\n",
       " (3680, 1),\n",
       " (3669, 224, 224, 3),\n",
       " (3669,),\n",
       " (3669, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = tfds.load('oxford_iiit_pet', split='train')\n",
    "test = tfds.load('oxford_iiit_pet', split='test')\n",
    "\n",
    "x_train, y_train, y_train2, x_test, y_test, y_test2 = [], [], [], [], [], []\n",
    "for i in train:\n",
    "    a = i['image'].numpy()\n",
    "    x_train.append(cv2.resize(a, (224, 224))/255.0)\n",
    "    y_train.append(i['label'].numpy())\n",
    "    y_train2.append(i['species'].numpy())\n",
    "    \n",
    "for i in test:\n",
    "    a = i['image'].numpy()\n",
    "    x_test.append(cv2.resize(a, (224, 224))/255.0)\n",
    "    y_test.append(i['label'].numpy())\n",
    "    y_test2.append(i['species'].numpy())\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train2 = np.array(y_train2)\n",
    "y_train2 = np.expand_dims(y_train2, axis=1)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test2 = np.array(y_test2)\n",
    "y_test2 = np.expand_dims(y_test2, axis=1)\n",
    "\n",
    "x_train.shape, y_train.shape, y_train2.shape, x_test.shape, y_test.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df2964fe-4383-4dd5-b816-bebcd4cc0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification for two classes\n",
    "class Model1(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.base_model = ResNet50(include_top=False)\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(1000, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(256, activation='relu')\n",
    "        self.out = keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "# classification for 37 classes\n",
    "class Model2(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.base_model = ResNet50(include_top=False)\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(1000, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(256, activation='relu')\n",
    "        self.out = keras.layers.Dense(37, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "model1 = Model1()\n",
    "model2 = Model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a382b5ac-85b4-4cd4-bc68-db24a74370a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "loss_object1 = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer1 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss1 = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy1 = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss1 = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy1 = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')\n",
    "\n",
    "# optimize functions\n",
    "@tf.function\n",
    "def train_step1(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model1(images, training=True)\n",
    "        loss = loss_object1(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model1.trainable_variables)\n",
    "    optimizer1.apply_gradients(zip(gradients, model1.trainable_variables))\n",
    "\n",
    "    train_loss1(loss)\n",
    "    train_accuracy1(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step1(images, labels):\n",
    "    predictions = model1(images, training=False)\n",
    "    t_loss = loss_object1(labels, predictions)\n",
    "    \n",
    "    test_loss1(t_loss)\n",
    "    test_accuracy1(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67f2ead-3628-4d68-a1f9-aad21bed5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer2 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss2 = tf.keras.metrics.Mean(name='train_loss2')\n",
    "train_accuracy2 = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy2')\n",
    "\n",
    "test_loss2 = tf.keras.metrics.Mean(name='test_loss2')\n",
    "test_accuracy2 = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy2')\n",
    "\n",
    "# optimize functions\n",
    "@tf.function\n",
    "def train_step2(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model2(images, training=True)\n",
    "        loss = loss_object2(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model2.trainable_variables)\n",
    "    optimizer2.apply_gradients(zip(gradients, model2.trainable_variables))\n",
    "\n",
    "    train_loss2(loss)\n",
    "    train_accuracy2(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step2(images, labels):\n",
    "    predictions = model2(images, training=False)\n",
    "    t_loss = loss_object2(labels, predictions)\n",
    "    \n",
    "    test_loss2(t_loss)\n",
    "    test_accuracy2(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "646d5e53-fe3c-4648-8bf5-4ca18fdc38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2 classes\n",
    "train_gen1 = DataGenerator(x_train, y_train2, 32)\n",
    "test_gen1 = DataGenerator(x_test, y_test2, 32)\n",
    "\n",
    "# for 37 classes\n",
    "train_gen2 = DataGenerator(x_train, y_train, 32)\n",
    "test_gen2 = DataGenerator(x_test, y_test, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2922355-2c67-4f81-94e4-a46649243767",
   "metadata": {},
   "source": [
    "### Train 2 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8285d024-4db3-49e1-b7aa-c647b4074813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6312733292579651, Accuracy: 63.4782600402832%, Test Loss: 0.6858803033828735, Test Accuracy: 67.42981719970703%\n",
      "Epoch 1, Loss: 0.46277353167533875, Accuracy: 79.02174377441406%, Test Loss: 0.6545984148979187, Test Accuracy: 67.78413391113281%\n",
      "Epoch 2, Loss: 0.4017350375652313, Accuracy: 71.875%, Test Loss: 0.6450284719467163, Test Accuracy: 48.105751037597656%\n",
      "Epoch 3, Loss: 0.3220498263835907, Accuracy: 90.0815200805664%, Test Loss: 0.7781049013137817, Test Accuracy: 66.88470458984375%\n",
      "Epoch 4, Loss: 0.48381155729293823, Accuracy: 68.75%, Test Loss: 0.7099180221557617, Test Accuracy: 33.142547607421875%\n",
      "Epoch 5, Loss: 0.5750225782394409, Accuracy: 65.84239196777344%, Test Loss: 0.6556015014648438, Test Accuracy: 68.54728698730469%\n",
      "Epoch 6, Loss: 0.5842815041542053, Accuracy: 59.15760803222656%, Test Loss: 0.7064923644065857, Test Accuracy: 34.17824935913086%\n",
      "Epoch 7, Loss: 0.6620802283287048, Accuracy: 66.25%, Test Loss: 0.65508633852005, Test Accuracy: 67.7023696899414%\n",
      "Epoch 8, Loss: 0.630115807056427, Accuracy: 68.50543975830078%, Test Loss: 0.6310034990310669, Test Accuracy: 67.83865356445312%\n",
      "Epoch 9, Loss: 0.6238914728164673, Accuracy: 68.31521606445312%, Test Loss: 0.6576938629150391, Test Accuracy: 66.85746002197266%\n",
      "Epoch 10, Loss: 0.5599929094314575, Accuracy: 74.89130401611328%, Test Loss: 0.6310860514640808, Test Accuracy: 67.83865356445312%\n",
      "Epoch 11, Loss: 0.6255176067352295, Accuracy: 68.07064819335938%, Test Loss: 0.6285256147384644, Test Accuracy: 67.83865356445312%\n",
      "Epoch 12, Loss: 0.6246170997619629, Accuracy: 68.07064819335938%, Test Loss: 0.6282509565353394, Test Accuracy: 67.83865356445312%\n",
      "Epoch 13, Loss: 0.6245387196540833, Accuracy: 68.07064819335938%, Test Loss: 0.6282162070274353, Test Accuracy: 67.83865356445312%\n",
      "Epoch 14, Loss: 0.6245368123054504, Accuracy: 68.07064819335938%, Test Loss: 0.6282092928886414, Test Accuracy: 67.83865356445312%\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss1.reset_states()\n",
    "    train_accuracy1.reset_states()\n",
    "    test_loss1.reset_states()\n",
    "    test_accuracy1.reset_states()\n",
    "\n",
    "    for train_images, train_labels in train_gen1:\n",
    "        train_step1(train_images, train_labels)\n",
    "\n",
    "    for test_images, test_labels in test_gen1:\n",
    "        test_step1(test_images, test_labels)\n",
    "    if epoch % 1 == 0:\n",
    "        print(\n",
    "          f'Epoch {epoch}, '\n",
    "          f'Loss: {train_loss1.result()}, '\n",
    "          f'Accuracy: {train_accuracy1.result() * 100}%, '\n",
    "          f'Test Loss: {test_loss1.result()}, '\n",
    "          f'Test Accuracy: {test_accuracy1.result() * 100}%'\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec0735-2150-4bef-a838-c5c4967d6ad7",
   "metadata": {},
   "source": [
    "### Train 37 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96263c9b-a4bd-4eb5-b63f-208c6d5584cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.6116199493408203, Accuracy: 2.5543477535247803%, Test Loss: 3.6109049320220947, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 1, Loss: 3.611973285675049, Accuracy: 2.5271739959716797%, Test Loss: 3.6109001636505127, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 2, Loss: 3.6110823154449463, Accuracy: 2.58152174949646%, Test Loss: 3.6108968257904053, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 3, Loss: 3.6114296913146973, Accuracy: 2.4728260040283203%, Test Loss: 3.6108946800231934, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 4, Loss: 3.611266613006592, Accuracy: 2.3097825050354004%, Test Loss: 3.6108925342559814, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 5, Loss: 3.611266851425171, Accuracy: 2.2282607555389404%, Test Loss: 3.6108932495117188, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 6, Loss: 3.611267566680908, Accuracy: 2.1467392444610596%, Test Loss: 3.6108932495117188, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 7, Loss: 3.611269474029541, Accuracy: 2.1467392444610596%, Test Loss: 3.610893487930298, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 8, Loss: 3.6112709045410156, Accuracy: 2.11956524848938%, Test Loss: 3.610891819000244, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 9, Loss: 3.6112723350524902, Accuracy: 2.1467392444610596%, Test Loss: 3.610891580581665, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 10, Loss: 3.6112732887268066, Accuracy: 1.95652174949646%, Test Loss: 3.6108930110931396, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 11, Loss: 3.611274242401123, Accuracy: 1.79347825050354%, Test Loss: 3.610893726348877, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 12, Loss: 3.611276149749756, Accuracy: 1.9021738767623901%, Test Loss: 3.6108946800231934, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 13, Loss: 3.6112759113311768, Accuracy: 1.95652174949646%, Test Loss: 3.6108951568603516, Test Accuracy: 2.7255382537841797%\n",
      "Epoch 14, Loss: 3.6112773418426514, Accuracy: 1.8206522464752197%, Test Loss: 3.610895872116089, Test Accuracy: 2.7255382537841797%\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss2.reset_states()\n",
    "    train_accuracy2.reset_states()\n",
    "    test_loss2.reset_states()\n",
    "    test_accuracy2.reset_states()\n",
    "\n",
    "    for train_images, train_labels in train_gen2:\n",
    "        train_step2(train_images, train_labels)\n",
    "\n",
    "    for test_images, test_labels in test_gen2:\n",
    "        test_step2(test_images, test_labels)\n",
    "    if epoch % 1 == 0:\n",
    "        print(\n",
    "          f'Epoch {epoch}, '\n",
    "          f'Loss: {train_loss2.result()}, '\n",
    "          f'Accuracy: {train_accuracy2.result() * 100}%, '\n",
    "          f'Test Loss: {test_loss2.result()}, '\n",
    "          f'Test Accuracy: {test_accuracy2.result() * 100}%'\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0b9ef-098f-4b79-8f02-83e8100c4e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
